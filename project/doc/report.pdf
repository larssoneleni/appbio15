Reducing noise in protein multialignments
Eleni Charlotta Larsson Stockholms University larsson.eleni@gmail.com January 11, 2016
1
Abstract In this project report the goal where to investigate the eﬃciency of removing ”noisy” positions in protein sequences when creating newick trees for evolutionary studies. By noisy it is meant that several amino acids in the same position in diﬀerent sequences have a large variability or a high instances of indels. A program where created in python that placed sequences next to each other and removed noisy elements by column reduction. The reduced data along with unaltered data where then used to build newick trees using the programs fastprot and fnj. These trees where then compared against a reference tree to ﬁnd the amount of trees that where correctly reproduced. The diﬀerences between the amount of reproduced trees created by reducing the data and the amount of reproduced trees created by the unaltered data where statistically analysed to see if the reduced data gave more reproduced trees than the unaltered data. It was found that it could only be statistically proven in one case where the data had high symmetry. The hypothesis for this where that symmetrical elements compensated for the removed noisy columns.
1
Introduction In several ﬁeld of medicine and biology there exists a need for determining evolutionary linkage between diﬀerent strands of biological sequences. In order to determine the evolutionary origins of a biological sequence one can use multiple sequence alignments. A multiple sequence alignment is sequences alignments of several (three or more) biological stands of ether DNA, protein or rna from diﬀerent species[1]. In this project the focus is on protein sequences. A multiple sequence alignment is used to build a ”newick” tree which is a evolutionary tree that is readable for a computer and thus allows faster computation.
However, multialigemnts are ”noisy”. By noisy it is meant that several amino acids in the same position in diﬀerent sequences have a large variability or a high instances of indels. To indicate these positions each sequence is put in a matrix so relevant positions are placed in the same column. Noisy positions are then the columns with high variability, meaning that at least 50% of the amino acids are unique and no amino acid appears more than twice, or columns with a substantial amount of indels, meaning more than 50% of the column contains indels. These are considered bad columns[2].
This report aims to investigate if removal of such noisy positions can proved a higher amount of correct newick trees, meaning more sequences can be evolutionary coupled to each other.
Materials and Methods During this project a method of noise reduction where created. This noise reduction method where then applied to given input data. After this, newick trees where generated for both the unaltered input data and the data achieved by the noise reduced model. The resulting data where then compared with a reference tree to investigate how many recoveredtreeswhereobtainedbyreducingnoisyelementsandfromunaltered. Thenoise reduction method where implemented in using the programing language python and run on a computer utilizing the Ubuntu operating system.
Test data descriptions The data contains of six categoris that is placed in six subdirectories. These are named: asymmetric 0.5, asymmetric 1.0, asymmetric 2.0, symmetric 0.5, symmetric 1.0, symmetric 2.0. Each directory has one reference tree and 300 alignments in it. These alignments where created by using muscle to align the resulting sequences created by evolving along the reference tree. The reference trees are either symmetric or asymmetric due to the number of mutation per site in the sequences. The mutation rate is given in the subdirectories names (0.5, 1.0, 2.0), where the 2.0 has two mutations per sequence position.
The programs To calculate the amount of reference trees that was recovered with the two methods three program was created in Python. To start with the program Column was made. The ﬁrst program created where named Column. This consisted of four functions:
2
-SeqDiq - This function takes a FASTA ﬁle and places the names of the species as a key in a dictionary and the sequences that correspond to the names as their values. -order-ThisfunctiontakesaFASTAﬁle. Thefunctiontakestheorderofthespecies and places that number as a key in a dictionary and the name of the species as the value. -SameLength - This function takes the dictionary that was created in SeqDic and checks if the values has the same length. If the length is not the same it exit the program with an error message. -column - This function takes a FASTA ﬁle. It creates a dictionary with the SeqDic function. This directory is then looped over to make a dictionary containing the numbers from 0 to the length of the sequences minus 1 as the keys. The values are the amino acids at the same position as the key.
After the program Column was made the program ReducingNoise where created. This program consisted of four functions as well.
-Indels - This function takes a FASTA ﬁle. It creates a dictionary by using the function column from the program Column. It loops over the keys in the dictionary and places the positions (keys) where the values consist of more than 50% indels(”-”) in a list. -Unique - This function takes a FASTA ﬁle. It creates a dictionary by using the function column from the program Column. It loops over the keys in the dictionary and places the positions (keys) where at least 50% of the amino acids in the values are unique in a list. -MoreThan2- This function takes a FASTA ﬁle. It creates a dictionary by using the function column from the program Column. It loops over the keys in the dictionary and places the positions (keys) where no amino acids in the values appears more than twice in a list. -TakeAway - This function takes a FASTA ﬁle. It creates a dictionary by using the function SeqDic from the program Column and three list by using the functions Indels, Unique and MoreThan2. The function combines the lists and takes away the numbers that appears more than twice. It then removes the positions that is given from the list in the values in the dictionary. It also checks if the new dictionary is empty and if so it exit the program with an error message.
The last program that was created was the Main program. The Main program takes one or more directories. This program uses the fastprot and fnj programs to create the newnick trees for both the reduced data and the unaltered data. Both the reduced data and the unaltered data has a counter for the times the newnick tree is recovered. The program prints out this two counter to standard out at the end of the run. The program also checks if the ﬁles in the directories except the reference tree is FASTA ﬁles. If not, the program exit with an error message.
Organization of the project TheprojectwasorganizedwithhelpoftheNoble’ssuggestions[3]. Theprojectisuploaded to the GitHub website. The project has the appbio15 directory as the root. Appbio15 is the directory project and it consist of ﬁve subdirectories: bin, data, doc, results and src. The bin directory has all the ﬁnish code. The data directory consist of the six subdirectories with the test data. The doc directory has the project report as a text ﬁle and as a pdf ﬁle. The results directory consist of the notebook where one writes the
3
dates,whathasbeendone,resultsandquestions. Theresultsalsoconsistofsubdirectories named with the date they were created. In this directories one can ﬁnd the code that has been test runned that day and the results each test run has given. The src directory consist of the source code.
Results The program Main returned the number of times the reference tree was recovered for the two methods, as shown in Table 1. The recovery rate of the trees follows an Bernoulli distribution, thus to calculate the mean and standard variation for the Bernoulli distribution the following two formulas where used[4]: E[X]=PN i=1 xi N = p, σ =pp(1−p), where N is the number of ﬁles and xi = 0 or xi = 1. The mean and standard derivation for each subdirectory can be found in Table 2. To see if the reduced data gives more recovered trees than the unaltered data, a test variable was design. The distribution of the unaltered and reduced data can be approximated to follow a normal distribution because the central limit theorem states this is possible for data with large size N, as it was for the data. The distribution for the reduced case was N(µ,σ1) and for the unaltered N(µ+∆,σ2). Inthisprojectthesamplinginpairsmethodwhereusedtoﬁndoutthetest variable because the reduced data and the unaltered data can be seen as pairs. To use the sampling in pairs method one has to take the amount of reduced data and subtract the amount of unaltered data. This will give the distribution N(∆,σ1+σ2) and it was on this distribution the test variable where created from. The formula for the test variable is as follows[4]: T = ¯ X−∆0 σ/√N , where ¯ X =PN i=1(xi −yi) and ∆0 = 0. The results for the test variable can be found inTabell 1 .
Directories Unaltered Reduced Files T symmetric 0.5 23 25 300 90.30 symmetric 1.0 17 12 300 -285.75 symmetric 2.0 4 3 300 -114.07 asymmetric 0.5 1 1 300 0 asymmetric 1.0 0 0 300 X asymmetric 2.0 0 0 300 X Table1: Tableofthenumberoftimesthereferencetreeisrecoveredforboththeunaltered data and the reduced data, the number of ﬁles in each subdirectories that contains the test data and the test variable (T) for the subdirectory. X means that no test variable where calculated (further explanation found in the Discussion section).
4
Reduced/Unaltered Directories Mean sd Reduced symmetric 0.5 0.083 0.28 Reduced symmetric 1.0 0.040 0.20 Reduced symmetric 2.0 0.010 0.099 Reduced asymmetric 0.5 0.0033 0.058 Reduced asymmetric 1.0 0 0 Reduced asymmetric 2.0 0 0 Unaltered symmetric 0.5 0.077 0.27 Unaltered symmetric 1.0 0.057 0.23 Unaltered symmetric 2.0 0.013 0.11 Unaltered asymmetric 0.5 0.0033 0.058 Unaltered asymmetric 1.0 0 0 Unaltered asymmetric 2.0 0 0 Table 2: The mean and standard derivation (sd) for every subdirectory that is containing the test data. The mean and sd is calculated both on the reduced data and the unaltered data.
Discussion Results For the subdirectories symmetric 1.0 and asymmetric 2.0 no test was done. This decision was made because the number of times the reference tree was recovered for the reduced data and the unaltered data was equal to zero. Therefore one get a nominator and a denominator that equals to zero and this derivation leads to mathematically insigniﬁcant results. For these two directories there can’t be any deﬁnitive conclusions and thus they are left out of this discussion. The null hypnosis was H0 : ∆ ≤ 0 and the alternative hypothesis was H1 : ∆ > 0. This hypothesis gave the critical area C ={T ≥ λα}. In this project, α was chosen to be 0.00005 which gives the critical area C = {T ≥ 3.89}[4]. In Table 1 one can see that for the data in the symmetric 0.5 directory the null hypothesis can be rejected on the signiﬁcant level 0.005% but for the other directories this can’t be done, even for a significant level of 5%. From this the conclusion was made that for the symmetric 0.5 it was bettertousethereduceddatabutfortheotheronesnodeﬁnitiveconclusioncanbemade.
The conclusion for the whole test data was that it depends on how symmetric the alignments are if it is worth going through a reduction algorithm or not. The presented hypothesis for this result is as follows. For more symmetric input alignments it is beneﬁcial to remove ”noisy” positions because other correct positions will compensate by their symmetry for the loss of bad columns. However, as the data becomes more asymmetric this compensation is reduced and less correct trees can be found.
5
Structure The project structure where inspired of Noble’s suggestions. However, all of suggestions where not followed. For example the dates in the data directory was removed due to the fact that the test data was only inserted once. In the beginning the structure of the results directory where diﬀerent. For instance ﬁles such as ”Code1Column2015-12-22” and ”Res1Column2015-12-22” where ﬁrst created. But this structure became to diﬃcult to organize ﬁles and thus the structure was redone to what is described in the Materials and Methods section. Noble also suggested that dates can be used to connect the diﬀerent part in the project. This was used in this project because the author thought it was an easy way to ﬁnd relevant code. Also the bin, src and doc directories is used becauseitmakesiteasytoﬁndandconnectthereport, code, notebookandtheresults[3].
6
References [1] Multiple Sequence Alignment https://gtbinf.wordpress.com/biol-41506150/ multiple-sequence-alignment/. [2] Reducing noise in protein multialignments https://www.kth. se/social/course/DD2404/subgroup/ht-2015-appbio15/page/ reducing-noise-in-protein-multialignment-2/. [3] William Staﬀord Noble A Quick Guide to Organizing Computational Biology Projects http://journals.plos.org/ploscompbiol/article?id=10.1371/ journal.pcbi.1000424. [4] Alm, Sven E. and Britton, Tom. 2008. Stokastik, Sannoliklhetsteori och statistkteori med till¨ampningar. 1. ed. Liber.
7
